# ===========================================
# Docker Compose - Development: API
# ===========================================
# Usage: docker compose -f docker-compose.dev.api.yml up -d
# Purpose: Run API + Ollama in Docker, debug UI locally
# UI connects to API at http://localhost:13245
# ===========================================

services:
  api:
    build:
      context: ./Api
      dockerfile: Dockerfile
    container_name: raysoncv-api
    restart: unless-stopped
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      Cors__AllowedOrigins__0: http://localhost:3000
      Cors__AllowedOrigins__1: http://localhost:5173
      LOG_LEVEL: Debug
      OLLAMA__BASEURL: http://ollama:11434
    ports:
      - "13245:8080"
    depends_on:
      ollama:
        condition: service_healthy
    networks:
      - internal
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ===========================================
  # Ollama (AI Chatbot)
  # ===========================================
  ollama:
    build:
      context: .
      dockerfile: ollama.Dockerfile
    container_name: raysoncv-ollama
    restart: unless-stopped
    environment:
      OLLAMA_HOST: 0.0.0.0
    volumes:
      - ollama-data:/root/.ollama
    ports:
      - "11435:11434"
    networks:
      - internal
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:11434/api/tags | grep -q smollm2"]
      interval: 5s
      timeout: 10s
      retries: 180
      start_period: 0s

networks:
  internal:
    driver: bridge

volumes:
  ollama-data:
